optimizer:
  type: "Adam"
  learning_rate: 0.001
  weight_decay: 0.0001

loss_function: "cross_entropy"

training:
  batch_size: 32
  num_epochs: 100
  early_stopping_patience: 10

scheduler:
  type: "ReduceLROnPlateau"
  factor: 0.5
  patience: 5

checkpointing:
  save_best_only: true
  checkpoint_dir: "models/checkpoints"
